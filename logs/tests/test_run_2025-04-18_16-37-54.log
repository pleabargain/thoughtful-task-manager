2025-04-18 16:37:54 [    INFO] Starting test session. Logging to: C:\Users\denni\Documents\thoughtful task manager\logs\tests\test_run_2025-04-18_16-37-54.log (conftest.py:70)
2025-04-18 16:37:54 [    INFO] Test passed: test_task_from_dict_with_id (conftest.py:82)
2025-04-18 16:37:54 [    INFO] Test passed: test_task_with_id_parameter (conftest.py:82)
2025-04-18 16:37:54 [    INFO] Test passed: test_file_handler_load_tasks_structure (conftest.py:82)
2025-04-18 16:37:54 [    INFO] Test passed: test_priority_validation_direct (conftest.py:82)
2025-04-18 16:37:54 [    INFO] Test passed: test_load_tasks_empty_file (conftest.py:82)
2025-04-18 16:37:54 [    INFO] Test passed: test_load_tasks_direct_list (conftest.py:82)
2025-04-18 16:37:54 [    INFO] Test passed: test_load_tasks_with_tasks_key (conftest.py:82)
2025-04-18 16:37:54 [    INFO] Test passed: test_save_and_load_tasks (conftest.py:82)
2025-04-18 16:37:54 [    INFO] Test passed: test_client_initialization (conftest.py:82)
2025-04-18 16:37:58 [    INFO] Test passed: test_connection_retry (conftest.py:82)
2025-04-18 16:37:58 [    INFO] Test passed: test_model_list_command (conftest.py:82)
2025-04-18 16:37:58 [    INFO] Test passed: test_model_name_parsing (conftest.py:82)
2025-04-18 16:37:58 [    INFO] Test passed: test_model_verification_failure (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_ollama_service_running (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_load_tasks (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_add_task (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_update_task (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_delete_task (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_get_task (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_task_creation (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_task_to_dict (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_task_from_dict (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_task_with_id (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_task_to_dict_with_id (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_task_from_dict_with_id (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_priority_validation_string (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_priority_validation_out_of_range_high (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_priority_validation_out_of_range_low (conftest.py:82)
2025-04-18 16:38:00 [    INFO] Test passed: test_priority_validation_non_integer (conftest.py:82)
2025-04-18 16:38:06 [   ERROR] Test failed: test_complete_task_lifecycle (conftest.py:84)
2025-04-18 16:38:06 [   ERROR] Failure details:
self = <tests.test_user_input.TestUserInput testMethod=test_complete_task_lifecycle>, mock_ask = <MagicMock name='ask' id='2740700284256'>

    @patch('rich.prompt.Prompt.ask')
    def test_complete_task_lifecycle(self, mock_ask):
        """Test the complete lifecycle of a task from creation to completion."""
        # Mock user inputs for creating a task
        mock_ask.side_effect = [
            "1",  # View tasks (initially empty)
            "2",  # Add task
            "Complete Project Documentation",  # Task title
            "Write comprehensive documentation for the project",  # Description
            "5",  # Priority (high)
            "3",  # Update task
            "Complete Project Documentation",  # Task to update
            "status",  # What to update
            "in_progress",  # New status
            "3",  # Update task again
            "Complete Project Documentation",  # Task to update
            "status",  # What to update
            "completed",  # New status
            "1",  # View tasks (now with completed task)
            "8"   # Exit
        ]
    
        # Run the application with mocked input
        with patch('rich.console.Console.print') as mock_print:
            try:
                self.task_manager.run()
            except SystemExit:
                pass  # Expected when exiting
    
        # Verify the task was saved to the file with the correct status
        with open(self.data_file, 'r') as f:
            saved_data = json.load(f)
    
        self.assertEqual(len(saved_data), 1)
        saved_task = saved_data[0]
        self.assertEqual(saved_task["title"], "Complete Project Documentation")
        self.assertEqual(saved_task["description"], "Write comprehensive documentation for the project")
        self.assertEqual(saved_task["priority"], 5)
>       self.assertEqual(saved_task["status"], "completed")
E       AssertionError: 'pending' != 'completed'
E       - pending
E       + completed

tests\test_user_input.py:65: AssertionError (conftest.py:86)
2025-04-18 16:38:10 [    INFO] Test passed: test_delete_task (conftest.py:82)
2025-04-18 16:38:15 [    INFO] Test passed: test_task_priority_validation (conftest.py:82)
2025-04-18 16:38:15 [    INFO] Test session completed (conftest.py:72)
